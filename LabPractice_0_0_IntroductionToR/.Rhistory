h=12) #Forecast horizon
tail(y.TR*10)
val.forecast_h12*10
# Sigue una continuacion logica para el forecast:
autoplot(cbind(y.TV, x.TV), facets=TRUE)
y.TV.est <- rep(NA, length(y.TV))
for (i in seq(length(y.TR)+1, length(y), 1)){
y.TV.est[i] <- TF.forecast(y.old = subset(y, end=i-1),
x.old = subset(x, end = i-1),
x.new = subset(x, start = i, end = i),
model = TF.fit,
h = 1)
}
y.TV.est <- na.omit(y.TV.est)
head(y.TV.est)
head(y.TV)
accuracy(y.TV.est, y.TV*10)
# RMSE - 10.11478
plot(y.TV*10)
plot(y.TV.est)
#Plot series and forecast (! Important)
autoplot(y.TV*10)+
forecast::autolayer(ts(y.TV.est))
# Bueno, hora de pasar al siguiente ejercicio que se me hace tarde:
#Problem 2: (5 points)
#The dataset Prob2.dat contains two non-seasonal time series: the input x and the output y.
#Questions:
#  1. Identify a nonlinear model to predict one step ahead values of the output variable y,
#     using 80% of the data.
#  2. Diagnose your proposed model.
#  3. Validate your model using the remaining 20% of the data.
fdata_mlp <- read.table("Prob2.dat", header = TRUE) # Si el archivo .dat chueco.
head(fdata_mlp)
fdata_ts_mlp <- ts(fdata_mlp)
y.mlp <- fdata_ts_mlp[,2]
x.mlp <- fdata_ts_mlp[,1]
y.mlp.TR <- subset(y.mlp, end = length(y.mlp)*0.8)
y.mlp.TV <- subset(y.mlp, start = length(y.mlp)*0.8 + 1 )
x.mlp.TR <- subset(x.mlp, end = length(x.mlp)*0.8)
x.mlp.TV <- subset(x.mlp, start = length(x.mlp)*0.8 + 1)
"contains two non-seasonal time series"
# Genial, vamos a ver ahora. Dudas dudas.
ggtsdisplay(y)
# Vale, aqui va a hacer falta diferenciacion como la copa de un pino. <- Que expresion tan curiosa.
ggtsdisplay(x)
fdata.REG <- fdata_ts[]
#"contains two non-seasonal time series"
# Genial, vamos a ver ahora. Dudas dudas.
ggtsdisplay(y.mlp.TR)
# Vale, aqui va a hacer falta diferenciacion como la copa de un pino. <- Que expresion tan curiosa.
ggtsdisplay(x.mlp.TR)
fdata_mlp.REG <- fdata_ts_mlp[,c(1,2)]
#Vamos a diferenciar las series a ver que nos sale
#* 9: En caso de que no lleve fecha - Diferenciar para averiguar la ventana temporal. z for Box-Cox, y for normal.
# Differentiation: if the ACF decreases very slowly -> needs differenciation
ggtsdisplay(y, lag.max = 100)
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(y, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12) # differences contains the order of differentiation
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(x, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12)
# Let's go!
fdata_mlp.Reg$x_lag1 <- Lag(fdata_mlp$x,1)
fdata_mlp.Reg <- fdata_ts_mlp[,c(1,2)]
#Vamos a diferenciar las series a ver que nos sale
#* 9: En caso de que no lleve fecha - Diferenciar para averiguar la ventana temporal. z for Box-Cox, y for normal.
# Differentiation: if the ACF decreases very slowly -> needs differenciation
ggtsdisplay(y, lag.max = 100)
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(y, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12) # differences contains the order of differentiation
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(x, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12)
# Let's go!
fdata_mlp.Reg$x_lag1 <- Lag(fdata_mlp$x,1)
fdata_mlp.Reg$x_lag2 <- Lag(fdata_mlp$x,2)
fdata_mlp.Reg$x_lag3 <- Lag(fdata_mlp$x,3)
fdata_mlp.Reg$y_lag1 <- Lag(fdata_mlp$y,1)
fdata_mlp.Reg$y_lag2 <- Lag(fdata_mlp$y,2)
fdata_mlp.Reg$y_lag3 <- Lag(fdata_mlp$y,3)
# ? - Part II Remove the NA's caused by the lag
#Notice that the begining of the time series contains NA due to the new lagged series
head(fdata_mlp.Reg)
fdata_mlp.Reg <- fdata_mlp[,c(1,2)]
#Vamos a diferenciar las series a ver que nos sale
#* 9: En caso de que no lleve fecha - Diferenciar para averiguar la ventana temporal. z for Box-Cox, y for normal.
# Differentiation: if the ACF decreases very slowly -> needs differenciation
ggtsdisplay(y, lag.max = 100)
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(y, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12) # differences contains the order of differentiation
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(x, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12)
# Let's go!
fdata_mlp.Reg$x_lag1 <- Lag(fdata_mlp$x,1)
fdata_mlp.Reg$x_lag2 <- Lag(fdata_mlp$x,2)
fdata_mlp.Reg$x_lag3 <- Lag(fdata_mlp$x,3)
fdata_mlp.Reg$y_lag1 <- Lag(fdata_mlp$y,1)
fdata_mlp.Reg$y_lag2 <- Lag(fdata_mlp$y,2)
fdata_mlp.Reg$y_lag3 <- Lag(fdata_mlp$y,3)
# ? - Part II Remove the NA's caused by the lag
#Notice that the begining of the time series contains NA due to the new lagged series
head(fdata_mlp.Reg)
# Let's go!
fdata_mlp.Reg$x_lag1 <- Lag(fdata_mlp$x.mlp.TR,1)
fdata_mlp.Reg$x_lag2 <- Lag(fdata_mlp$x.mlp.TR,2)
fdata_mlp.Reg$x_lag3 <- Lag(fdata_mlp$x.mlp.TR,3)
fdata_mlp.Reg$y_lag1 <- Lag(fdata_mlp$y.mlp.TR,1)
fdata_mlp.Reg$y_lag2 <- Lag(fdata_mlp$y.mlp.TR,2)
fdata_mlp.Reg$y_lag3 <- Lag(fdata_mlp$y.mlp.TR,3)
# ? - Part II Remove the NA's caused by the lag
#Notice that the begining of the time series contains NA due to the new lagged series
head(fdata_mlp.Reg)
fdata.Reg.tr <- fdata.Reg
# Let's go!
fdata_mlp.Reg$x_lag1 <- Lag(fdata_mlp$x.mlp.TR,1)
# Bueno, hora de pasar al siguiente ejercicio que se me hace tarde:
#Problem 2: (5 points)
#The dataset Prob2.dat contains two non-seasonal time series: the input x and the output y.
#Questions:
#  1. Identify a nonlinear model to predict one step ahead values of the output variable y,
#     using 80% of the data.
#  2. Diagnose your proposed model.
#  3. Validate your model using the remaining 20% of the data.
fdata_mlp <- read.table("Prob2.dat", header = TRUE) # Si el archivo .dat chueco.
head(fdata_mlp)
fdata_ts_mlp <- ts(fdata_mlp)
y.mlp <- fdata_ts_mlp[,2]
x.mlp <- fdata_ts_mlp[,1]
y.mlp.TR <- subset(y.mlp, end = length(y.mlp)*0.8)
y.mlp.TV <- subset(y.mlp, start = length(y.mlp)*0.8 + 1 )
x.mlp.TR <- subset(x.mlp, end = length(x.mlp)*0.8)
x.mlp.TV <- subset(x.mlp, start = length(x.mlp)*0.8 + 1)
#"contains two non-seasonal time series"
# Genial, vamos a ver ahora. Dudas dudas.
ggtsdisplay(y.mlp.TR)
# Vale, aqui va a hacer falta diferenciacion como la copa de un pino. <- Que expresion tan curiosa.
ggtsdisplay(x.mlp.TR)
# Esto que no sea la time series
fdata_mlp.Reg <- fdata_mlp[,c(1,2)]
#Vamos a diferenciar las series a ver que nos sale
#* 9: En caso de que no lleve fecha - Diferenciar para averiguar la ventana temporal. z for Box-Cox, y for normal.
# Differentiation: if the ACF decreases very slowly -> needs differenciation
ggtsdisplay(y, lag.max = 100)
#Vamos a diferenciar las series a ver que nos sale
#* 9: En caso de que no lleve fecha - Diferenciar para averiguar la ventana temporal. z for Box-Cox, y for normal.
# Differentiation: if the ACF decreases very slowly -> needs differenciation
ggtsdisplay(y.mlp, lag.max = 100)
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(y, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12) # differences contains the order of differentiation
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(y.mlp, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12) # differences contains the order of differentiation
# ? - Parte I: Diferenciación Regular  - d
Bz <- diff(x.mlp, differences = 1)
ggtsdisplay(Bz, lag.max = 4 * 12)
# Let's go!
fdata_mlp.Reg$x_lag1 <- Lag(fdata_mlp$x.mlp.TR,1)
# Let's go! (Vale, entonces, e)
fdata_mlp.Reg$x_lag1 <- Lag(x.mlp.TR,1)
fdata_mlp.Reg$x_lag2 <- Lag(x.mlp.TR,2)
fdata_mlp.Reg$x_lag3 <- Lag(x.mlp.TR,3)
# Let's go! (Vale, entonces esto se tiene que hacer con la columna entera, no la time series de entrenamiento)
fdata_mlp.Reg$x_lag1 <- Lag(fdata_mlp$x,1)
fdata_mlp.Reg$x_lag2 <- Lag(fdata_mlp$x,2)
fdata_mlp.Reg$x_lag3 <- Lag(fdata_mlp$x,3)
fdata_mlp.Reg$y_lag1 <- Lag(fdata_mlp$y,1)
fdata_mlp.Reg$y_lag2 <- Lag(fdata_mlp$y,2)
fdata_mlp.Reg$y_lag3 <- Lag(fdata_mlp$y,3)
# ? - Part II Remove the NA's caused by the lag
#Notice that the begining of the time series contains NA due to the new lagged series
head(fdata_mlp.Reg)
fdata.Reg.tr <- fdata.Reg
#Remove missing values
fdata.Reg.tr <- na.omit(fdata.Reg.tr)
fdata_mlp.Reg.tr <- fdata_mlp.Reg
#Remove missing values
fdata_mlp.Reg.tr <- na.omit(fdata_mlp.Reg.tr)
fdata_mlp.Reg.tr
# * 3. Set up the Cross-Validation with 10 folds
ctrl_tune <- trainControl(method = "cv",
number = 10,
summaryFunction = defaultSummary,    #Performance summary for comparing models in hold-out samples.
savePredictions = TRUE)              #save predictions
# * 4. Neural Network setup [TRAINING]
#------------ Neural network --------------------------------
set.seed(150) #For replication
mlp.fit = train(form = y~., #Use formula method to account for categorical variables
data = fdata_mlp.Reg.tr,
method = "nnet",
linout = TRUE,
# tuneGrid = data.frame(size =5, decay = 0),
tuneGrid = expand.grid(size = seq(5,15,length.out =3), decay =  10^(c(-3:0))),
maxit = 200,
preProcess = c("center","scale"),
trControl = ctrl_tune,
metric = "RMSE")
mlp.fit #information about the resampling settings
ggplot(mlp.fit)+scale_x_log10() # ! - Pues aqui la verdad es que no me acuerdo muy bien.
plotnet(mlp.fit$finalModel) #Plot the network -> Aqui debemos de observar, en cual de ellas contribuye (Grosor de las lineas)
SensAnalysisMLP(mlp.fit) #Statistical sensitivity analysis -> Sensibilidad de contribución de las entradas.
set.seed(150) #For replication
set.seed(150) #For replication
mlp.fit2 = train(form = y~y_lag1+x_lag1+x_lag3, #Use formula method to account for categorical variables the most significant
data = fdata_mlp.Reg.tr,
method = "nnet",
linout = TRUE,
# tuneGrid = data.frame(size =5, decay = 0),
tuneGrid = expand.grid(size = seq(5,20,by=5), decay =  10^(seq(-3,0))),
maxit = 200,
preProcess = c("center","scale"),
trControl = ctrl_tune,
metric = "RMSE")
mlp.fit2 #information about the resampling settings
ggplot(mlp.fit2)+scale_x_log10() # REDUCE NUMBER OF NEURONS?
plotnet(mlp.fit2$finalModel) #Plot the network -> Aqui debemos de observar, en cual de ellas contribuye (Grosor de las lineas)
SensAnalysisMLP(mlp.fit2) #Statistical sensitivity analysis -> Sensibilidad de contribución de las entradas.
# * 5. Predict Training Data + Observar discrepancias
#Predict training data
mlp_pred = predict(mlp.fit2,  newdata = fdata_mlp.Reg.tr)
# ? - Esto se encarga de observar la relación entre los factores y la predicción de la y
PlotModelDiagnosis(fdata_mlp.Reg.tr[,-1], fdata_mlp.Reg.tr[,1], mlp_pred, together = TRUE)
#Error measurements
accuracy(fdata.Reg.tr[,1],mlp_pred)
#Error measurements
accuracy(fdata_mlp.Reg.tr[,1],mlp_pred)
head(fdata_mlp.Reg.tr)
#Error measurements
accuracy(fdata_mlp.Reg.tr[,2],mlp_pred)
# ? - Esto se encarga de observar la relación entre los factores y la predicción de la y
PlotModelDiagnosis(fdata_mlp.Reg.tr[,-1], fdata_mlp.Reg.tr[,2], mlp_pred, together = TRUE)
#Error measurements
accuracy(fdata_mlp.Reg.tr[,2],mlp_pred)
head(fdata_mlp.Reg.tr)
plot(fdata.Reg.tr[21],type="l")
plot(fdata.Reg.tr[,2],type="l")
plot(fdata_mlp.Reg.tr[,2],type="l")
lines(mlp_pred,col = "red")
setwd("~/Desktop/My stuff/ICAI/ML 2/Retake_2021")
library(MLTools)
library(caret)
library(kernlab)
library(nnet)
library(NeuralNetTools)
library(NeuralSens)
library(Hmisc)
library(forecast)
z <- read.table("Prob2.dat", header=TRUE)
head(z)
ggtsdisplay(ts(z$y))
z <- read.table("Prob2.dat", header=TRUE)
head(z)
setwd("~/Desktop/My stuff/ICAI/Segundo Cuatri/Estadistica Comp/Intro-Estadistica-Computacional/LabPractice_0_0_IntroductionToR")
state.df = data.frame(state.x77, Region=state.region, Division=state.division)
state.df <- data.frame(state.df, Abbr = state.abb)
head(state.df, 3)
state.df <- state.df[, -which(colnames(state.df) == "Region")]
head(state.df, 3)
state.df$Center.x <- state.center$x
state.df$Center.y <- state.center$y
head(state.df)
filtered_df_manual <- state.df[state.df$Center.x < -100,]
filtered_df_manual <- state.df[state.df$Center.x < -100,]
# Check if the two data frames are equal
data_frames_equal <- identical(filtered_df_manual, filtered_df_subset)
filtered_df_manual <- state.df[state.df$Center.x < -100,]
# Check if the two data frames are equal
data_frames_equal <- identical(filtered_df_manual, state.df[state.df$Center.x < -100,])
# Print the result
print(data_frames_equal)
filtered_df <- subset(state.df, Center.x < - 100 & MurderRate > 9)
filtered_df <- subset(state.df, Center.x < - 100 & Murder > 9)
print(filtered_df)
max_life_exp_index <- which.max(filtered_df$LifeExp)
print(filtered_df[max_life_exp_index, ])
x.squared <- 999
huber(x = 3)
huber = function(x, a=1) {
x.squared = x^2
ifelse(abs(x) <= a, x.squared, 2*a*abs(x)-a^2)
}
x.squared <- 999
huber(x = 3)
print(x.squared)
x.squared <- 999
huber(x = 3) # 5
print(x.squared) # 999
x.squared <- "Hello, Jaime!"
huber(x = 3)
print(x.squared)
x.squared <- 999
huber(x = 3) # 5
print(x.squared) # 999
x.squared <- "Hello, Jaime!"
huber(x = 3) # 5
print(x.squared) #"Hello, Jaime!"
x.squared <- 42
huber(x = 3)
print(x.squared)
a <- -59.6
huber(x = 3, a =2)
print(a)
a <- -59.6
huber(x = 3, a =2) # 8
print(a) # - 59.6
a <- "Hello, Jaime!"
huber(x = 3,a = 2) # 5
print(a) #"Hello, Jaime!"
a <- 42
huber(x = 3, a = 2) # 5
print(a) # 42
# Define huber.sloppy
huber.sloppy = function(x) {
ifelse(abs(x) <= a, x^2, 2*a*abs(x)-a^2)
}
# Set a globally and call huber.sloppy
a <- 1.5
print(huber.sloppy(x=3))  # Expected to use a=1.5 in its calculation
a <- 2
print(huber.sloppy(x=3))  # Expected to use a=2 in its calculation
a <- 0.5
print(huber.sloppy(x=3))  # Expected to use a=0.5 in its calculation
# Challenge: Set a to a string and call huber.sloppy
a <- "test"
print(huber.sloppy(x=3))
# Correct use in global scope
a <- 5  # Assigns 5 to 'a' in the global environment
print(a)  # Should print 5
# Attempting to use <- within a function call (Hypothetical and incorrect)
# huber(x <- 3, a <- 5)  # This is not valid R syntax and would throw an error
# Correctly calling a function with an argument
# Assuming 'a' is not a parameter of 'huber', this sets 'a' globally before calling the function
a <- 5  # This changes 'a' globally
result <- huber(a=5)  # Sets 'a' only within the call to 'huber'
# Correct use in global scope
a <- 5  # Assigns 5 to 'a' in the global environment
print(a)  # Should print 5
# Attempting to use <- within a function call (Hypothetical and incorrect)
huber(x <- 3, a <- 5)  # This is not valid R syntax and would throw an error
# Correctly calling a function with an argument
# Assuming 'a' is not a parameter of 'huber', this sets 'a' globally before calling the function
a <- 5  # This changes 'a' globally
result <- huber(a=5)  # Sets 'a' only within the call to 'huber'
# Correct use in global scope
a <- 5  # Assigns 5 to 'a' in the global environment
print(a)  # Should print 5
# Attempting to use <- within a function call (Hypothetical and incorrect)
huber(x <- 3, a <- 5)  # This did work and assigned it
# Correctly calling a function with an argument
# Assuming 'a' is not a parameter of 'huber', this sets 'a' globally before calling the function
x <- 5  # This changes 'a' globally
result <- huber(x=5)  # Sets 'a' only within the call to 'huber'
print(x)  # Still prints 5, assuming 'huber' does not modify 'a' globally
huber = function(x, a=1) {
ifelse(abs(x) <= a, x^2, 2*a*abs(x)-a^2)
}
huber(x=3, b <- 20)
print(b)
plot(seq(0, 2, length.out = 50), 0.05*seq(0, 2, length.out = 50)^2 - sin(seq(0, 2, length.out = 50))*cos(seq(0, 2, length.out = 50)) + 0.1*exp(1+log(seq(0, 2, length.out = 50))))
x <- seq(0, 2, length.out = 50); plot(x, 0.05*x^2 - sin(x)*cos(x) + 0.1*exp(1+log(x)))
my_function <- function() {
x <- 10
}
# Calling the function
my_function()
# Trying to access x outside the function
print(x)
my_function <- function() {
y <- 10
}
# Calling the function
my_function()
# Trying to access x outside the function
print(y)
# A hook to wrap output based on a linewidth chunk option
# From https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE, linewidth=79)
# A hook to wrap output based on a linewidth chunk option
# From https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE, linewidth=79)
install.packages("tidyverse")
install.packages("repurrrsive")
library(purrr)
library(dplyr)
library(tidyr)
library(repurrrsive)
letters %>%
toupper %>%
paste(collapse="+")
paste(toupper(letters), collapse = '+')
"     Ceci n'est pas une pipe     " %>%
gsub("une", "un", .) %>%
trimws
"     Ceci n'est pas une pipe     " %>%
gsub("une", "un", .) %>%
trimws
trimws(gsub("une", "un", "     Ceci n'est pas une pipe     "))
rnorm(1000) %>%
hist(breaks=30, main="N(0,1) draws", col="pink", prob=TRUE)
hist(rnorm(1000), breaks = 30, main = "N(0,1) draws", col = "pink", prob = TRUE)
max(hist(rnorm(1000), breaks = 30, plot = FALSE)$density)
rnorm(1000) %>%
hist(breaks=30, plot=FALSE) %>%
`[[`("density") %>%
max
sample(c("A", "B", "C", "D", "R"), size = 1) %>%
paste("Your grade is", .)
paste("Your grade is", sample(c("A","B","C","D","R"), size=1))
paste("Your grade is", sample(c("A","B","C","D","R"), size=1))
paste("Your grade is", sample(c("A","B","C","D","R"), size=1))
sample(c("A", "B", "C", "D", "R"), size = 1) %>%
paste("Your grade is", .)
sample(c("A", "B", "C", "D", "R"), size = 1) %>%
paste("Your grade is", .)
sample(c("A", "B", "C", "D", "R"), size = 1) %>%
paste("Your grade is", .)
state.name[which.max(state.x77[,"Illiteracy"])]
state.x77 %>%
`[` , "Illiteracy" %>%
state.x77 %>%
`[` , "Illiteracy" %>%
state.x77 %>%
`[` , "Illiteracy" %>%
state.x77 %>%
`[`  "Illiteracy" %>%
#library(magrittr)
state.name[state.x77 %>% `[`(., which.max(.$Illiteracy)), ]
library(magrittr)
state.name[state.x77 %>% `[`(., which.max(.$Illiteracy)), ]
library(magrittr)
state.name[state.x77 %>%
`[`(., which.max(.$Illiteracy)), ]
library(magrittr)
state.name[state.x77 %>%
`[`(., which.max(.$Illiteracy)), ]
state.name[state.x77 %>%
`[`(., which.max("Illiteracy")), ]
str.url = "http://www.stat.cmu.edu/~ryantibs/statcomp/data/king.txt"
lines = readLines(str.url)
text = paste(lines, collapse=" ")
words = strsplit(text, split="[[:space:]]|[[:punct:]]")[[1]]
wordtab = table(words)
wordtab = sort(wordtab, decreasing=TRUE)
head(wordtab, 10)
str.url <- "http://www.stat.cmu.edu/~ryantibs/statcomp/data/king.txt"
wordtab <- str.url %>%
readLines() %>%
paste(collapse = " ") %>%
strsplit(split = "[[:space:]]|[[:punct:]]") %>%
`[[`(1) %>%
table() %>%
sort(decreasing = TRUE)
head(wordtab, 10)
state.name[which.max(state.x77[,"Illiteracy"])]
state.name <- state.name %>% {.[which.max(state.x77[["Illiteracy"]])]}
state_illiteracy <- tibble(StateName = state.name, Illiteracy = state.x77[,"Illiteracy"]) %>%
filter(!is.na(Illiteracy)) %>% # Remove NA values if needed
arrange(-Illiteracy) %>%
head(1) %>%
pull(StateName)
print(state_illiteracy)
state_illiteracy <- tibble(StateName = state.name, Illiteracy = state.x77[,"Illiteracy"]) %>%
arrange(-Illiteracy) %>%
head(1) %>%
pull(StateName)
print(state_illiteracy)
str.url <- "http://www.stat.cmu.edu/~ryantibs/statcomp/data/king.txt"
wordtab <- str.url %>%
readLines() %>%
paste(collapse = " ") %>%
strsplit(split = "[[:space:]]|[[:punct:]]") %>%
`[[`(1) %>%
table() %>%
sort(decreasing = TRUE)
head(wordtab, 10)
wordtab <- str.url %>%
readLines() %>%
paste(collapse = " ") %>%
strsplit(split = "[[:space:]]|[[:punct:]]") %>%
pluck(1) %>%
discard(~ . == "") %>%
table() %>%
sort(decreasing = TRUE)
head(wordtab, 10)
