summary(bin.draws.0.5)
# The result shows the minimum, 1st Quartile, Median, Mean, 3rd Quartile and Maximum of the vector. The quartiles are around 1.5 from the mean, # which are narrower than the standard deviation as expected. As 1 standard deviation from the mean contain around 67% of the values and 1 quartile away contain around 50% of the values.
str(bin.draws.0.5)
# It prints the vector in a string and shows the type of the values within the vector.
cat("The values within the vector are of type: ",typeof(bin.draws.0.5))
# Transform to Char:
bin.draws.0.5.char <- as.character(bin.draws.0.5)
typeof(bin.draws.0.5.char)
summary(bin.draws.0.5.char)
# The summary function now shows the number of characters rather than statistical measures, as the vector does not represent numbers anymore.
hist(bin.draws.0.5)
plot(bin.draws.0.5)
# The function plot() is plotting the index on the x axis and the value on the y axis.
# Showing a discrete graph with values in between 15 and 0, and most values being at 7,8,9,10.
setwd("~/Desktop/My stuff/ICAI/Segundo Cuatri/Estadistica Comp/Intro-Estadistica-Computacional/LabPractice_0_0_IntroductionToR")
library(readr)
library(officer)
data1 <- read.table("Simdata1.csv",sep=";",header=TRUE) # Regression
data2 <- read.table("Simdata2.csv",sep=";",header=TRUE) # Classification
length(unique(data2[,ncol(data2)]))
data3 <- read.table("Simdata3.csv",sep=";",header=TRUE) # Regression
data4 <- read.table("Simdata4.csv",sep=";",header=TRUE) # Classification
length(unique(data4[,ncol(data4)]))
data5 <- read.table("Simdata5.csv",sep=";",header=TRUE) # Classification
length(unique(data5[,ncol(data5)]))
data6 <- read.table("Simdata6.csv",sep=";",header=TRUE) # Regression
data7 <- read.table("Simdata7.csv",sep=";",header=TRUE) # Classification
length(unique(data7[,ncol(data7)]))
datasets <- list(data1, data2, data3, data4, data5, data6, data7)
class(data4$Y) %in% c("character", "integer")
for (i in seq_along(datasets)) {
# Check if the last column is either character or integer
if (class(datasets[[i]][, ncol(datasets[[i]])]) %in% c("character", "integer")) {
datasets[[i]]$Y <- as.factor(datasets[[i]]$Y)
}
}
#data5$Y <- as.factor(data5[,ncol(data5)])
#data5[,ncol(data5)]
for (i in seq_along(datasets)) {
# Check if the last column is either character or integer
if (class(datasets[[i]][, ncol(datasets[[i]])]) %in% c("character", "integer")) {
datasets[[i]]$Y <- as.factor(datasets[[i]]$Y)
}
}
length(unique(data2[,ncol(data2)]))
length(unique(data4[,ncol(data4)]))
length(unique(data5[,ncol(data5)]))
length(unique(data7[,ncol(data7)]))
datasets <- list(data1, data2, data3, data4, data5, data6, data7)
class(data4$Y) %in% c("character", "integer")
View(datasets)
class(data4$Y) %in% c("character", "integer")
for (i in seq_along(datasets)) {
# Check if the last column is either character or integer
if (class(datasets[[i]][, ncol(datasets[[i]])]) %in% c("character", "integer")) {
datasets[[i]]$Y <- as.factor(datasets[[i]]$Y)
}
}
View(data4)
View(data4)
View(data5)
View(data5)
View(data6)
View(data6)
View(data7)
View(data7)
# Check missing values:
# Check for missing values in each dataset
for (i in seq_along(datasets)) {
# Check for missing values
missing_values <- sum(is.na(datasets[[i]]))
if (missing_values > 0) {
print(paste("Number of missing values in data", i, ":", missing_values))
} else {
print(paste("No missing values in data", i))
}
}
detect_outliers <- function(dataset, num_columns) {
# This function assumes that the first 'num_columns' in the dataset are the input columns
# Initialize a vector to store the count of outliers for each column
outliers_count <- rep(0, num_columns)
# Go through each of the specified input columns to detect outliers
for (i in 1:num_columns) {
# Extract the column by index
column_data <- dataset[, i]
# Compute the IQR
Q1 <- quantile(column_data, 0.25)
Q3 <- quantile(column_data, 0.75)
IQR <- Q3 - Q1
# Determine the bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Count outliers
outliers_count[i] <- sum(column_data < lower_bound | column_data > upper_bound)
}
# Return the count of outliers for each column
return(outliers_count)
}
outlier_count_1 <- detect_outliers(data1, 1)
outlier_count_7 <- detect_outliers(data7, 2)
print(outlier_count_1)
print(outlier_count_7)
detect_outliers <- function(dataset, num_columns) {
# This function assumes that the first 'num_columns' in the dataset are the input columns
# Initialize a vector to store the count of outliers for each column
outliers_count <- rep(0, num_columns)
# Go through each of the specified input columns to detect outliers
for (i in 1:num_columns) {
# Extract the column by index
column_data <- dataset[, i]
# Compute the IQR
Q1 <- quantile(column_data, 0.25)
Q3 <- quantile(column_data, 0.75)
IQR <- Q3 - Q1
# Determine the bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Count outliers
outliers_count[i] <- sum(column_data < lower_bound | column_data > upper_bound)
}
# Return the count of outliers for each column
return(outliers_count)
}
outlier_count_1 <- detect_outliers(data1, 1)
outlier_count_2 <- detect_outliers(data2, 2)
detect_outliers <- function(dataset, num_columns) {
# This function assumes that the first 'num_columns' in the dataset are the input columns
# Initialize a vector to store the count of outliers for each column
outliers_count <- rep(0, num_columns)
# Go through each of the specified input columns to detect outliers
for (i in 1:num_columns) {
# Extract the column by index
column_data <- dataset[, i]
# Compute the IQR
Q1 <- quantile(column_data, 0.25)
Q3 <- quantile(column_data, 0.75)
IQR <- Q3 - Q1
# Determine the bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Count outliers
outliers_count[i] <- sum(column_data < lower_bound | column_data > upper_bound)
}
# Return the count of outliers for each column
return(outliers_count)
}
# Remove N.A's
for (i in seq_along(datasets)) {
# Remove NA values from the dataset
cleaned_datasets[[i]] <- na.omit(list_of_datasets[[i]])
# Optionally, you can assign the cleaned dataset back to the original variable
# assign(paste0('df', i), cleaned_datasets[[i]])
}
detect_outliers <- function(dataset, num_columns) {
# This function assumes that the first 'num_columns' in the dataset are the input columns
# Initialize a vector to store the count of outliers for each column
outliers_count <- rep(0, num_columns)
# Go through each of the specified input columns to detect outliers
for (i in 1:num_columns) {
# Extract the column by index
column_data <- dataset[, i]
# Compute the IQR
Q1 <- quantile(column_data, 0.25)
Q3 <- quantile(column_data, 0.75)
IQR <- Q3 - Q1
# Determine the bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Count outliers
outliers_count[i] <- sum(column_data < lower_bound | column_data > upper_bound)
}
# Return the count of outliers for each column
return(outliers_count)
}
# Remove N.A's
for (i in seq_along(datasets)) {
# Remove NA values from the dataset
cleaned_datasets[[i]] <- na.omit(datasets[[i]])
# Optionally, you can assign the cleaned dataset back to the original variable
# assign(paste0('df', i), cleaned_datasets[[i]])
}
detect_outliers <- function(dataset, num_columns) {
# This function assumes that the first 'num_columns' in the dataset are the input columns
# Initialize a vector to store the count of outliers for each column
outliers_count <- rep(0, num_columns)
# Go through each of the specified input columns to detect outliers
for (i in 1:num_columns) {
# Extract the column by index
column_data <- dataset[, i]
# Compute the IQR
Q1 <- quantile(column_data, 0.25)
Q3 <- quantile(column_data, 0.75)
IQR <- Q3 - Q1
# Determine the bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Count outliers
outliers_count[i] <- sum(column_data < lower_bound | column_data > upper_bound)
}
# Return the count of outliers for each column
return(outliers_count)
}
cleaned_datasets <- list()
# Remove N.A's
for (i in seq_along(datasets)) {
# Remove NA values from the dataset
cleaned_datasets[[i]] <- na.omit(datasets[[i]])
# Optionally, you can assign the cleaned dataset back to the original variable
# assign(paste0('df', i), cleaned_datasets[[i]])
}
outlier_count_1 <- detect_outliers(data1, 1)
outlier_count_2 <- detect_outliers(data2, 2)
detect_outliers <- function(dataset, num_columns) {
# This function assumes that the first 'num_columns' in the dataset are the input columns
# Initialize a vector to store the count of outliers for each column
outliers_count <- rep(0, num_columns)
# Go through each of the specified input columns to detect outliers
for (i in 1:num_columns) {
# Extract the column by index
column_data <- dataset[, i]
# Compute the IQR
Q1 <- quantile(column_data, 0.25)
Q3 <- quantile(column_data, 0.75)
IQR <- Q3 - Q1
# Determine the bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Count outliers
outliers_count[i] <- sum(column_data < lower_bound | column_data > upper_bound)
}
# Return the count of outliers for each column
return(outliers_count)
}
outlier_count_1 <- detect_outliers(data1, 1)
outlier_count_2 <- detect_outliers(na.omit(data2), 2)
outlier_count_3 <- detect_outliers(data3, 1)
outlier_count_4 <- detect_outliers(data4, 2)
outlier_count_5 <- detect_outliers(data5, 2)
outlier_count_6 <- detect_outliers(data1, 1)
outlier_count_7 <- detect_outliers(data7, 2)
# data1
ggplot(data1, aes(x = V1, y = V2)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
library(ggplot2)
# data1
ggplot(data1, aes(x = V1, y = V2)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data1
ggplot(data1, aes(x = X1, y = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data2
ggplot(data1, aes(x = V1, y = V2)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data7
ggplot(data1, aes(x = X1, y = X2)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data7
ggplot(data7, aes(x = X1, y = X2)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data1
ggplot(data1, aes(x = X1, y = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data7
ggplot(data7, aes(x = X1, y = X2)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data7") +
theme_minimal()
# data7
ggplot(data7, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data7") +
theme_minimal()
# data7
ggplot(data7, aes(x = X1, y = X2, color = Y)) +
geom_point() +
theme_minimal() +
labs(color = 'Z Value')  # Label for the color scale
# data1
ggplot(data1, aes(x = X1, y = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data7
ggplot(data7, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data7") +
theme_minimal()
# data1
ggplot(data1, aes(x = X1, y = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data2
ggplot(data2, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data2") +
theme_minimal()
# data7
ggplot(data7, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data7") +
theme_minimal()
#data3
ggplot(data3, aes(x = X1, y = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data3") +
theme_minimal()
# data4
ggplot(data7, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data4") +
theme_minimal()
# data4
ggplot(data4, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data4") +
theme_minimal()
# data5
ggplot(data5, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data5") +
theme_minimal()
# data1
ggplot(data1, aes(x = X1, y = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data1") +
theme_minimal()
# data2
ggplot(data2, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data2") +
theme_minimal()
#data3
ggplot(data3, aes(x = X1, y = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data3") +
theme_minimal()
# data4
ggplot(data4, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data4") +
theme_minimal()
# data5
ggplot(data5, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data5") +
theme_minimal()
#data6
ggplot(data6, aes(x = X1, y = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data6") +
theme_minimal()
# data7
ggplot(data7, aes(x = X1, y = X2, color = Y)) +
geom_point(size = 3) +
labs(title = "2D Scatter Plot of data7") +
theme_minimal()
x.vec <- 1:100
# Check the length
length_x_vec <- length(x.vec)
# Report the data type stored in x.vec
data_type <- typeof(x.vec)
sum_x_vec <- sum(x.vec)
x.vec <- 1:100
# Check the length
length_x_vec <- length(x.vec) #100L
# Report the data type stored in x.vec
data_type <- typeof(x.vec) # integer
sum_x_vec <- sum(x.vec) #5050L
# Gauss's method to calculate the sum of an arithmetic series is the following formula:
# Sum = n/2 * (first_number + last_number) where n is the 100 terms in the series
gauss_sum <- length_x_vec / 2 * (x.vec[1] + x.vec[length_x_vec])
# Convert x.vec into a matrix with 20 rows and 5 columns, filled by columns (column-major order)
x.mat <- matrix(x.vec, nrow = 20, ncol = 5)
# Check the dimensions of x.mat
dim_x.mat <- dim(x.mat)
# Check the data type of x.mat
data_type_x.mat <- typeof(x.mat)
# Compute the sums of each of the 5 columns of x.mat
col_sums_x.mat <- colSums(x.mat)
# Check that the sum of column sums of x.mat equals the sum of x.vec
sum_col_sums_x.mat <- sum(col_sums_x.mat)
check_equality <- sum_col_sums_x.mat == sum(x.vec)
dim(x.mat)
typeof(x.mat)
colSums(x.mat)
sum(col_sums_x.mat)
sum_col_sums_x.mat == sum(x.vec)
x_mat[c(1, 5, 17), ]
x.mat[c(1, 5, 17), ]
sum(x_mat[2, ] > 40)
sum(x.mat[2, ] > 40)
sum(x_mat[, 3] > 45 & x_mat[, 3] < 50)
sum(x.mat[, 3] > 45 & x.mat[, 3] < 50)
sum(x_mat[, 5] %% 2 == 1)
sum(-_mat[, 5] %% 2 == 1)
sum(x.mat[, 5] %% 2 == 1)
sum(x.mat[, 3] > 45 & x.mat[, 3] < 50)
sum(x.mat[, 3] > 45 & x.mat[, 3] < 50) #4
sum(x.mat[2, ] > 40)
x.mat[c(1, 5, 17), ]
sum(x.mat[2, ] > 40) #3
sum(x.mat[, 3] > 45 & x.mat[, 3] < 50) #4
sum(x.mat[, 5] %% 2 == 1) #10
x.vec[x.vec %% 2 == 0] <- x.vec[x.vec %% 2 == 0] + 10
x.vec
x.vec <- ifelse(x.vec %% 2 == 0, x.vec + 10, x.vec)
x.vec
x.list[-2] # Extract all but the second element of the list
x.list = list(rnorm(6), letters, sample(c(TRUE,FALSE),size=4,replace=TRUE))
x.list[-2] # Extract all but the second element of the list
# Extract the Second Element of x.list as a Vector, and Then Extract the First 10 Elements of This Vector.
x.list[[2]][1:10]
x.list
pros.dat =
as.matrix(read.table("http://www.stat.cmu.edu/~ryantibs/statcomp/data/pros.dat"))
pros.dat
dim(pros.dat)
pros.dat[1:6, ]
pros.dat[(nrow(pros.dat)-5):nrow(pros.dat), ] # 3. Print last 6 rows and all columns
dim(pros.dat)                                 # 1. Dimensions of data: 97 rows by 9 columns
pros.dat[1:6, ]                               # 2. Preview of the first 6 rows
pros.dat[(nrow(pros.dat)-5):nrow(pros.dat), ] # 3. Print last 6 rows and all columns
# 1. First 6 rows
head(pros.dat, 6)
# 2. Last 6 rows
tail(pros.dat, 6)
colnames(pros.dat)
rownames(pros.dat)
pros.dat.sub <- pros.dat[,c("lcavol", "lweight")]
pros.dat.sub <- pros.dat[,c("lcavol", "lweight")]
dim(pros.dat.sub)
head(pros.dat.sub)
# Method 1: Using 3 function calls and one arithmetic operation
log_density_method1 <- log(exp(pros.dat.sub$lweight) / exp(pros.dat.sub$lcavol))
# Method 1: Using 3 function calls and one arithmetic operation
log_density_method1 <- log(exp(pros.dat.sub$lweight) / exp(pros.dat.sub$lcavol))
# Method 1: Using 3 function calls and one arithmetic operation
log_density_method1 <- log(exp(pros.dat.sub[, "lweight"]) / exp(pros.dat.sub[, "lcavol"]))
# Method 2: Using a single arithmetic operation - This works as divisions when it comes to logs are represented by subtractions.
log_density_method2 <- pros.dat.sub[, "lweight"] - pros.dat.sub[, "lcavol"]
# Verification that they give the same answer:
all.equal(log_density_method1, log_density_method2)
# Append log cancer density
pros.dat <- cbind(pros.dat, log_density_method2)
# Set the last column name to 'ldens'
colnames(pros.dat)[ncol(pros.dat)] <- "ldens"
# Print the first 6 rows of the updated pros.dat to check
head(pros.dat)
# Assuming the output variable 'y' is categorical and named as such
# For a bar plot of the output variable
barplot(table(data7$y), main="Bar Plot of Output Variable y", xlab="Classes", ylab="Frequency")
# For histograms of input variables x1 and x2
hist(data7$X1, main="Histogram of x1", xlab="x1")
hist(data7$X2, main="Histogram of x2", xlab="x2")
# Assuming the output variable 'y' is categorical and named as such
# For a bar plot of the output variable
barplot(table(data7$Y), main="Bar Plot of Output Variable y", xlab="Classes", ylab="Frequency")
library(ggplot2)
# Assuming data7 is your data frame and x1 is the input variable, y is the output variable
ggplot(data7, aes(x=x1)) +
geom_histogram(binwidth = 1) +
facet_wrap(~y) +
labs(title="Histogram of x1 by Output Variable y", x="x1", y="Count")
library(ggplot2)
# Assuming data7 is your data frame and x1 is the input variable, y is the output variable
ggplot(data7, aes(x=X1)) +
geom_histogram(binwidth = 1) +
facet_wrap(~Y) +
labs(title="Histogram of x1 by Output Variable y", x="x1", y="Count")
library(ggplot2)
# Assuming data7 is your data frame and x1 is the input variable, y is the output variable
ggplot(data7, aes(x=X2)) +
geom_histogram(binwidth = 1) +
facet_wrap(~Y) +
labs(title="Histogram of x1 by Output Variable y", x="X2", y="Count")
# Assuming data7 is your data frame and x1 is the input variable, y is the output variable
ggplot(data7, aes(x=X2)) +
geom_histogram(binwidth = 1) +
facet_wrap(~Y) +
labs(title="Histogram of X2 by Output Variable Y", x="X2", y="Count")
library(GGally)
install.packages("GGally")
library(GGally)
library(GGally)
# Example, applying ggpairs to the whole dataset
ggpairs(data7)
library(GGally)
plot_ggpairs_by_Y <- function(data) {
unique_Y <- unique(data$Y)
for (y_val in unique_Y) {
cat("Plotting for Y =", y_val, "\n")
data_subset <- subset(data, Y == y_val)
print(ggpairs(data_subset))
}
}
# Apply the function to your dataset
plot_ggpairs_by_Y(data7)
