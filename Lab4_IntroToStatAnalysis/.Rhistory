# Convert Time to numeric after removing quotes for men's dataset
sprint.m.df$Time <- as.numeric(gsub("\"", "", sprint.m.df$Time))
# Use tapply to compute the fastest time for each country in the men's dataset
fastest_times_men <- tapply(sprint.m.df$Time, sprint.m.df$Country, min, na.rm = TRUE)
# Convert the result to a data frame, sort it, and get the first 10 entries
fastest_times_men_df <- data.frame(Country = names(fastest_times_men), Fastest_Time = fastest_times_men)
fastest_times_men_df <- fastest_times_men_df[order(fastest_times_men_df$Fastest_Time), ]
head(fastest_times_men_df, 10)
# Convert Time to numeric after removing quotes for women's dataset
sprint.w.df$Time <- as.numeric(gsub("\"", "", sprint.w.df$Time))
# Use tapply to compute the fastest time for each country in the women's dataset
fastest_times_women <- tapply(sprint.w.df$Time, sprint.w.df$Country, min, na.rm = TRUE)
# Convert the result to a data frame, sort it, and get the first 10 entries
fastest_times_women_df <- data.frame(Country = names(fastest_times_women), Fastest_Time = fastest_times_women)
fastest_times_women_df <- fastest_times_women_df[order(fastest_times_women_df$Fastest_Time), ]
head(fastest_times_women_df, 10)
# For the men's dataset
fastest_men <- sprint.m.df %>%
mutate(Time = as.numeric(gsub("\"", "", Time))) %>%
arrange(Country, Time) %>%
group_by(Country) %>%
filter(Time == min(Time, na.rm = TRUE)) %>%
select(Name, City, Country, Time) %>%
ungroup() %>%
arrange(Time) %>%
slice_head(n = 10)
# For the women's dataset
fastest_women <- sprint.w.df %>%
mutate(Time = as.numeric(gsub("\"", "", Time))) %>%
arrange(Country, Time) %>%
group_by(Country) %>%
filter(Time == min(Time, na.rm = TRUE)) %>%
select(Name, City, Country, Time) %>%
ungroup() %>%
arrange(Time) %>%
slice_head(n = 10)
# Print the results
print(fastest_men)
print(fastest_women)
# Assuming sprint.m.df and sprint.w.df have been loaded into the R environment
# Define a custom function to find the fastest athlete per country
fastest_athlete <- function(df) {
df$Time <- as.numeric(gsub("\"", "", df$Time))
min_time <- min(df$Time, na.rm = TRUE)
fastest <- df[df$Time == min_time, ]
return(fastest)
}
# Apply the function to each subset of the data split by country
fastest_men <- do.call(rbind, lapply(split(sprint.m.df, sprint.m.df$Country), fastest_athlete))
fastest_women <- do.call(rbind, lapply(split(sprint.w.df, sprint.w.df$Country), fastest_athlete))
# Order the results by increasing time and select the first 10 rows
fastest_men_ordered <- fastest_men[order(fastest_men$Time), ][1:10, ]
fastest_women_ordered <- fastest_women[order(fastest_women$Time), ][1:10, ]
# Print the results
print(fastest_men_ordered)
print(fastest_women_ordered)
# Convert Time to numeric after removing quotes for the women's dataset
sprint.w.df$Time <- as.numeric(gsub("\"", "", sprint.w.df$Time))
# Order by Wind and then filter for times at most 10.7 seconds
fastest_women_under_10_7 <- sprint.w.df[sprint.w.df$Time <= 10.7, ]
fastest_women_under_10_7_ordered <- fastest_women_under_10_7[order(fastest_women_under_10_7$Wind), ]
# Display the result
print(fastest_women_under_10_7_ordered)
# Assuming sprint.w.df has been loaded into the R environment
# Convert Time to numeric after removing quotes
sprint.w.df$Time <- as.numeric(gsub("\"", "", sprint.w.df$Time))
# Order by Time, then Wind, filter for times at most 10.7 seconds, and select columns
fastest_women <- sprint.w.df[sprint.w.df$Time <= 10.7, ]
fastest_women_ordered <- fastest_women[order(fastest_women$Time, fastest_women$Wind), ]
selected_columns <- fastest_women_ordered[c("Time", "Wind", "Name", "Date")]
# Display the result
print(selected_columns)
# Convert Time to numeric after removing quotes
sprint.w.df$Time <- as.numeric(gsub("\"", "", sprint.w.df$Time))
# Subset the data where Wind values are nonpositive
nonpositive_wind_data <- sprint.w.df[sprint.w.df$Wind <= 0, ]
# Plot Time versus Wind
plot(Time ~ Wind, data=nonpositive_wind_data,
main="Time versus Wind for Nonpositive Wind Values",
xlab="Wind (m/s)", ylab="Time (seconds)",
pch=19, col="blue")
# Assuming sprint.w.df has been loaded into the R environment
# Convert Time to numeric after removing quotes
sprint.w.df$Time <- as.numeric(gsub("\"", "", sprint.w.df$Time))
# Subset the data where Wind values are nonpositive
nonpositive_wind_data <- sprint.w.df[sprint.w.df$Wind <= 0, ]
# Find the fastest Time for each Wind value
fastest_time_per_wind <- aggregate(Time ~ Wind, data = nonpositive_wind_data, min)
# Plot the fastest Time versus Wind
plot(Time ~ Wind, data = fastest_time_per_wind,
main = "Fastest Time versus Wind for Nonpositive Wind Values",
xlab = "Wind (m/s)", ylab = "Fastest Time (seconds)",
pch = 19, col = "blue")
# Confirm the data type of the Time column
class(sprint.m.df$Time)
# Convert the Time column to numeric, this will create NA values for non-convertible entries
sprint.m.df <- sprint.m.df %>%
mutate(Time_numeric = as.numeric(gsub("\"", "", Time)))
# Find the position of the NA values in the new Time_numeric column
na_positions <- which(is.na(sprint.m.df$Time_numeric))
# Inspect the original Time column for an NA position
sprint.m.df$Time[na_positions]
# Convert Time to numeric (handling the conversion issue)
sprint.m.df <- sprint.m.df %>%
mutate(Time = as.numeric(gsub("\"", "", Time, fixed = TRUE)))
# Create dat.reduced
dat.reduced <- sprint.m.df %>%
group_by(Name, City) %>%
summarize(Time = min(Time, na.rm = TRUE), .groups = 'drop') %>%
drop_na(Time)
# Confirm dimensions and display the first 10 rows
print(dim(dat.reduced))
print(head(dat.reduced, 10))
dat.wide <- dat.reduced %>%
arrange(City) %>%
pivot_wider(names_from = City, values_from = Time) %>%
arrange(Name)
# Confirm dimensions
print(dim(dat.wide))
non_na_count <- sum(!is.na(dat.wide[, -1])) # Exclude the first column (Name)
print(non_na_count)
# How to guess this number from dat.reduced
print(nrow(dat.reduced)) # This should match non_na_count
usain_bolt_cities_wide <- names(dat.wide)[which(!is.na(dat.wide[dat.wide$Name == "Usain Bolt", -1])) + 1]
print(usain_bolt_cities_wide)
# Directly from dat.reduced
usain_bolt_cities_reduced <- dat.reduced %>%
filter(Name == "Usain Bolt") %>%
pull(City)
print(usain_bolt_cities_reduced)
# Confirm they match
print(all(usain_bolt_cities_wide == usain_bolt_cities_reduced))
dat.long <- dat.wide %>%
pivot_longer(-Name, names_to = "City", values_to = "Time", values_drop_na = TRUE) %>%
arrange(Name, City)
# Confirm matching entries with dat.reduced
print(all.equal(dat.long, dat.reduced))
gc()
# A hook to wrap output based on a linewidth chunk option
# From https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE, linewidth=79)
library(testthat)
install.packages("covr")
library(covr)
#install.packages("covr")
#install.packages("testhat")
library(testhat)
#install.packages("covr")
#install.packages("testhat")
library(testthat)
library(covr)
C_to_F <- function(C_temp){
F_temp <- (C_temp * 9/5) + 32;
return(F_temp);
}
# YOUR CODE GOES HERE
test_that("Celsius to Fahrenheit conversion works correctly", {
expect_equal(C_to_F(0), 32)  # Testing the known conversion
expect_equal(C_to_F(100), 212)  # Boiling point of water
expect_equal(C_to_F(-40), -40)  # Point where Celsius equals Fahrenheit
})
F_to_C <- function(F_temp){
C_temp <- (F_temp - 32) * 5/9;
return(C_temp);
}
# YOUR CODE GOES HERE
test_that("Fahrenheit to Celsius conversion works correctly", {
expect_equal(F_to_C(32), 0)  # Testing the known conversion
expect_equal(F_to_C(212), 100)  # Boiling point of water
expect_equal(F_to_C(-40), -40)  # Point where Celsius equals Fahrenheit
})
test_dir(".")
setwd("~/Desktop/My stuff/ICAI/Cuatri II/5th-Year-Second-Term-ICAI/Estadistica Comp/Intro-Estadistica-Computacional/Lab3_Testing/Yago Tobio")
# A hook to wrap output based on a linewidth chunk option
# From https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE, linewidth=79)
#install.packages("covr")
#install.packages("testhat")
library(testthat)
library(covr)
# A hook to wrap output based on a linewidth chunk option
# From https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE, linewidth=79)
#install.packages("covr")
#install.packages("testhat")
library(testthat)
library(covr)
C_to_F <- function(C_temp){
F_temp <- (C_temp * 9/5) + 32;
return(F_temp);
}
# YOUR CODE GOES HERE
test_that("Celsius to Fahrenheit conversion works correctly", {
expect_equal(C_to_F(0), 32)  # Testing the known conversion
expect_equal(C_to_F(100), 212)  # Boiling point of water
expect_equal(C_to_F(-40), -40)  # Point where Celsius equals Fahrenheit
})
F_to_C <- function(F_temp){
C_temp <- (F_temp - 32) * 5/9;
return(C_temp);
}
# YOUR CODE GOES HERE
test_that("Fahrenheit to Celsius conversion works correctly", {
expect_equal(F_to_C(32), 0)  # Testing the known conversion
expect_equal(F_to_C(212), 100)  # Boiling point of water
expect_equal(F_to_C(-40), -40)  # Point where Celsius equals Fahrenheit
})
test_dir(".")
test_dir(".")
test_dir(".")
test_file("test-my_awesome_function.R")
# Constants
number_utility <- "number_utility"
extension_r <- ".R"
extension_htm <- ".htm"
# Manage file names
code_file_name <- paste(number_utility, extension_r, sep="")
test_file_name <- paste("test-", code_file_name, sep="")
coverage_report_file_name <- paste("coverage_report_", number_utility, extension_htm, sep="")
# Run tests and generate Code Coverage Report
test_file(test_file_name)
res <- file_coverage(code_file_name, test_file_name)
print(res)
report(res, coverage_report_file_name)
library(htmltools)
install.packages("DT")
#install.packages(htmltools)
#install.packages(DT)
library(htmltools)
library(DT)
# Constants
number_utility <- "number_utility"
extension_r <- ".R"
extension_htm <- ".htm"
# Manage file names
code_file_name <- paste(number_utility, extension_r, sep="")
test_file_name <- paste("test-", code_file_name, sep="")
coverage_report_file_name <- paste("coverage_report_", number_utility, extension_htm, sep="")
# Run tests and generate Code Coverage Report
test_file(test_file_name)
res <- file_coverage(code_file_name, test_file_name)
print(res)
report(res, coverage_report_file_name)
#install.packages(htmltools)
#install.packages(DT)
library(htmltools)
library(DT)
# Constants
number_utility <- "number_utility"
extension_r <- ".R"
extension_htm <- ".htm"
# Manage file names
code_file_name <- paste(number_utility, extension_r, sep="") #number_utility.R
test_file_name <- paste("test-", code_file_name, sep="").    #test-number_utility.R
#install.packages(htmltools)
#install.packages(DT)
library(htmltools)
library(DT)
# Constants
number_utility <- "number_utility"
extension_r <- ".R"
extension_htm <- ".htm"
# Manage file names
code_file_name <- paste(number_utility, extension_r, sep="") #number_utility.R
test_file_name <- paste("test-", code_file_name, sep="")   #test-number_utility.R
coverage_report_file_name <- paste("coverage_report_", number_utility, extension_htm, sep="")
#^^This generates the HTML file, with the coverage report for our testing.
# Run tests and generate Code Coverage Report
test_file(test_file_name)
res <- file_coverage(code_file_name, test_file_name)
print(res)
report(res, coverage_report_file_name)
tinytex::install_tinytex()
gc()
# A hook to wrap output based on a linewidth chunk option
# From https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE, linewidth=79)
install.packages("devtools")
install.packages("shiny")
devtools::install_github("StatsWithR/statsr")
library(statsr)
library(dplyr)
library(ggplot2)
data(nycflights)
setwd("~/Desktop/My stuff/ICAI/Cuatri II/5th-Year-Second-Term-ICAI/Estadistica Comp/Intro-Estadistica-Computacional/Lab4_IntroToStatAnalysis")
names(nycflights)
str(nycflights)
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram()
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram(binwidth = 15)
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram(binwidth = 150)
rdu_flights <- nycflights %>%
filter(dest == "RDU")
ggplot(data = rdu_flights, aes(x = dep_delay)) +
geom_histogram()
rdu_flights %>%
summarise(mean_dd = mean(dep_delay), sd_dd = sd(dep_delay), n = n())
sfo_feb_flights <- nycflights %>%
filter(dest == "SFO", month == 2)
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram(binwidth = 15)
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram(binwidth = 15)
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram(binwidth = 15)
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram(binwidth = 150)
# Assuming nycflights is the data frame containing all flights data
sfo_feb_flights <- nycflights %>%
filter(dest == "SFO", month == 2)
# To find out how many flights meet these criteria
num_sfo_feb_flights <- nrow(sfo_feb_flights)
print(num_sfo_feb_flights)
# To find out how many flights meet these criteria
num_sfo_feb_flights <- nrow(sfo_feb_flights)
print(num_sfo_feb_flights)
library(ggplot2)
library(dplyr)
# Histogram for arrival delays of sfo_feb_flights
ggplot(data = sfo_feb_flights, aes(x = arr_delay)) +
geom_histogram(binwidth = 15, fill = "blue", color = "black") +
labs(title = "Histogram of Arrival Delays for SFO February Flights",
x = "Arrival Delay (minutes)",
y = "Frequency") +
theme_minimal()
summary_stats <- sfo_feb_flights %>%
summarise(mean_arr_delay = mean(arr_delay, na.rm = TRUE),
sd_arr_delay = sd(arr_delay, na.rm = TRUE),
iqr_arr_delay = IQR(arr_delay, na.rm = TRUE),
min_arr_delay = min(arr_delay, na.rm = TRUE),
max_arr_delay = max(arr_delay, na.rm = TRUE),
n = n(),
n_missing = sum(is.na(arr_delay)))
print(summary_stats)
library(ggplot2)
library(dplyr)
# Histogram for arrival delays of sfo_feb_flights
ggplot(data = sfo_feb_flights, aes(x = arr_delay)) +
geom_histogram(binwidth = 15, fill = "blue", color = "black") +
labs(title = "Histogram of Arrival Delays for SFO February Flights",
x = "Arrival Delay (minutes)",
y = "Frequency") +
theme_minimal()
summary_stats <- sfo_feb_flights %>%
summarise(mean_arr_delay = mean(arr_delay, na.rm = TRUE),
sd_arr_delay = sd(arr_delay, na.rm = TRUE),
iqr_arr_delay = IQR(arr_delay, na.rm = TRUE),
min_arr_delay = min(arr_delay, na.rm = TRUE),
max_arr_delay = max(arr_delay, na.rm = TRUE),
median_arr_delay = median(arr_delay, na.rm = TRUE),
n = n(),
n_missing = sum(is.na(arr_delay)))
print(summary_stats)
library(ggplot2)
library(dplyr)
# Histogram for arrival delays of sfo_feb_flights
ggplot(data = sfo_feb_flights, aes(x = arr_delay)) +
geom_histogram(binwidth = 15, fill = "blue", color = "black") +
labs(title = "Histogram of Arrival Delays for SFO February Flights",
x = "Arrival Delay (minutes)",
y = "Frequency") +
theme_minimal()
summary_stats <- sfo_feb_flights %>%
summarise(mean_arr_delay = mean(arr_delay, na.rm = TRUE),
sd_arr_delay = sd(arr_delay, na.rm = TRUE),
iqr_arr_delay = IQR(arr_delay, na.rm = TRUE),
min_arr_delay = min(arr_delay, na.rm = TRUE),
max_arr_delay = max(arr_delay, na.rm = TRUE),
mean_arr_delay = mean(arr_delay, na.rm = TRUE),
median_arr_delay = median(arr_delay, na.rm = TRUE),
n = n(),
n_missing = sum(is.na(arr_delay)))
print(summary_stats)
# Assuming sfo_feb_flights is already loaded and filtered for SFO and February
# Calculate the median and IQR for arrival delays, grouped by carrier
carrier_stats <- sfo_feb_flights %>%
group_by(carrier) %>%
summarise(
median_arr_delay = median(arr_delay, na.rm = TRUE),
iqr_arr_delay = IQR(arr_delay, na.rm = TRUE),
.groups = 'drop'  # This drops the grouping structure afterwards
) %>%
arrange(desc(iqr_arr_delay))  # Arrange the results in descending order of IQR
# Print the statistics
print(carrier_stats)
# Carrier with the highest IQR of arrival delays
top_carrier_iqr <- carrier_stats[1, ]
print(top_carrier_iqr)
nycflights %>%
group_by(month) %>%
summarise(mean_dd = mean(dep_delay)) %>%
arrange(desc(mean_dd))
# Assuming nycflights is the data frame that contains all the flights data
monthly_avg_delays <- nycflights %>%
group_by(month) %>%
summarise(mean_dep_delay = mean(dep_delay, na.rm = TRUE)) %>%
arrange(desc(mean_dep_delay))
# View the results
print(monthly_avg_delays)
# Extracting the month with the highest average delay
highest_avg_delay_month <- monthly_avg_delays[1, ]
print(highest_avg_delay_month)
```{r highest-median-dep-delay-month}
monthly_median_delays <- nycflights %>%
group_by(month) %>%
summarise(median_dep_delay = median(dep_delay, na.rm = TRUE)) %>%
arrange(desc(median_dep_delay))
# View the results
print(monthly_median_delays)
# Extracting the month with the highest median delay
highest_median_delay_month <- monthly_median_delays[1, ]
print(highest_median_delay_month)
ggplot(nycflights, aes(x = factor(month), y = dep_delay)) +
geom_boxplot()
nycflights <- nycflights %>%
mutate(dep_type = ifelse(dep_delay < 5, "on time", "delayed"))
nycflights %>%
group_by(origin) %>%
summarise(ot_dep_rate = sum(dep_type == "on time") / n()) %>%
arrange(desc(ot_dep_rate))
ot_dep_rate <- nycflights %>%
group_by(origin) %>%
summarise(ot_dep_rate = sum(dep_type == "on time") / n()) %>%
arrange(desc(ot_dep_rate))
ot_dep_rate <- nycflights %>%
group_by(origin) %>%
summarise(ot_dep_rate = sum(dep_type == "on time") / n()) %>%
arrange(desc(ot_dep_rate))
print(ot_dep_rate)
# YOUR CODE GOES HERE
ot_dep_rate[1,]
ggplot(data = nycflights, aes(x = origin, fill = dep_type)) +
geom_bar()
nycflights <- nycflights %>%
mutate(avg_speed = (distance / (air_time / 60))) # air_time is in minutes, so divide by 60 to get hours
# Find the tail number of the plane with the fastest avg_speed
fastest_plane <- nycflights %>%
arrange(desc(avg_speed)) %>%
select(avg_speed, tailnum) %>%
slice(1)
# Print the tail number of the fastest plane
print(fastest_plane)
ggplot(nycflights, aes(x = distance, y = avg_speed)) +
geom_point() +
labs(title = "Average Speed vs. Distance",
x = "Distance (miles)",
y = "Average Speed (mph)") +
theme_minimal()
# YOUR CODE GOES HERE
on_time_arrival_proportion <- nycflights %>%
filter(dep_type == "delayed") %>%
summarise(on_time_percentage = mean(arr_type == "on time"))
nycflights <- nycflights %>%
mutate(arr_type = ifelse(arr_delay <= 0, "on time", "delayed"))
# Calculate the on-time arrival percentage for flights that were delayed departing
on_time_arrival_proportion <- nycflights %>%
filter(dep_type == "delayed") %>%
summarise(on_time_percentage = mean(arr_type == "on time"))
# Print the proportion
print(on_time_arrival_proportion)
utils::install.packages("devtools")
utils::contrib.url(repos, "source")
